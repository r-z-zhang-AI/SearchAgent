# 多轮对话LLM功能测试指南

## 🎯 核心功能测试

### 1. 基础教授推荐（第一轮）
**输入**: "推荐一个人工智能方向的导师"
**预期**:
- 返回教授推荐列表
- 显示简化后的研究方向（≤100字）
- 生成相关追问问题

### 2. 深入了解教授（第二轮）⭐
**输入**: "张三教授的研究方向能详细介绍一下吗？"
**预期**:
- 识别为 `professor_deep_inquiry` 类型
- 从上下文中识别出"张三教授"
- 生成详细的研究方向介绍（200-300字）
- 提供深入的追问选项

### 3. 使用代词的上下文跟进（第三轮）⭐
**输入**: "他有什么代表性的项目？"
**预期**:
- 识别为 `context_followup` 类型
- 正确解析"他"指向张三教授
- 返回项目相关信息
- 保持对话连贯性

### 4. 教授对比分析⭐
**输入**: "张三教授和李四教授在AI方面有什么区别？"
**预期**:
- 识别为 `professor_comparison` 类型
- 获取两位教授的详细信息
- 生成AI对比分析
- 突出各自特色和差异

### 5. 学术建议咨询⭐
**输入**: "我是本科生，想申请张三教授的研究生，需要什么条件？"
**预期**:
- 识别为 `academic_advice` 类型
- 识别用户角色为本科生
- 基于上下文中的张三教授信息
- 提供针对性的申请建议

## 🧠 上下文记忆测试

### 测试场景A: 连续询问同一教授
```
轮次1: "推荐AI导师" → [系统推荐张三教授]
轮次2: "张三教授主要研究什么？" → [详细研究介绍]
轮次3: "他的项目有哪些？" → [项目列表]
轮次4: "如何申请他的研究生？" → [申请建议]
```

### 测试场景B: 对比分析流程
```
轮次1: "推荐AI导师" → [推荐张三、李四教授]
轮次2: "这两个教授有什么区别？" → [对比分析]
轮次3: "哪个更适合本科生申请？" → [针对性建议]
```

### 测试场景C: 研究方向深入讨论
```
轮次1: "计算机视觉有什么发展前景？" → [研究讨论]
轮次2: "浙大这个方向的导师有哪些？" → [相关教授推荐]
轮次3: "这些导师的研究特色分别是什么？" → [详细对比]
```

## 🎛️ 意图识别验证

### 新增意图类型测试

#### professor_deep_inquiry
- ✅ "张三教授的研究方向详细介绍一下"
- ✅ "能具体说说李四教授做什么研究的吗？"
- ✅ "他的研究背景是什么？"

#### professor_comparison  
- ✅ "张三和李四教授在AI方面有什么不同？"
- ✅ "这几个教授哪个更厉害？"
- ✅ "对比一下他们的研究方向"

#### academic_advice
- ✅ "如何申请张三教授的研究生？"
- ✅ "我想读博士，有什么建议？"
- ✅ "本科生怎么提高科研能力？"

#### context_followup
- ✅ "他的主要成果是什么？"（指代前面提到的教授）
- ✅ "这个项目难度如何？"（指代前面讨论的项目）
- ✅ "那么申请条件呢？"（承接上文话题）

#### research_discussion
- ✅ "深度学习的发展趋势如何？"
- ✅ "计算机视觉在医疗中的应用前景？"
- ✅ "自然语言处理有哪些热点？"

## 📊 技术验证点

### 1. 上下文传递机制
```javascript
// 验证上下文结构
context: [
  {
    role: "user",
    content: "推荐AI导师",
    timestamp: "..."
  },
  {
    role: "assistant", 
    content: "为您推荐...",
    professors: [{"name": "张三", ...}],
    timestamp: "..."
  }
]
```

### 2. 实体识别准确性
- 教授姓名提取: "张三教授" → "张三"
- 代词解析: "他" → 上文中的"张三教授"  
- 技术领域识别: "人工智能、深度学习"

### 3. 响应元数据保存
```javascript
// 验证保存的元数据
message: {
  messageType: "professor_deep_inquiry",
  intent: {...},
  contextEntities: {
    professors: ["张三"],
    techDomains: ["人工智能"]
  },
  followupQuestions: [...]
}
```

### 4. AI简化功能集成
- 研究方向简化: ≤100字
- 匹配理由简化: ≤80字
- 保持专业性和可读性

## 🚨 边界情况测试

### 1. 上下文缺失
**输入**: "他的研究怎么样？"（没有前文提到教授）
**预期**: 请求澄清，询问具体指哪位教授

### 2. 模糊指代
**输入**: "这个项目的前景如何？"（前文提到多个项目）
**预期**: 请求明确指哪个项目

### 3. 跨话题切换
**输入**: 从AI话题突然切换到材料科学
**预期**: 正确识别新话题，重置相关上下文

### 4. 长对话记忆
**输入**: 超过6轮对话后的上下文处理
**预期**: 保留最近6轮对话，自动截断早期内容

## 🎮 用户体验验证

### 1. 流式生成体验
- 思考时间预测准确
- 流式显示流畅自然
- 中断/继续功能正常

### 2. 追问建议质量
- 追问问题相关性高
- 引导用户深入对话
- 问题表述清晰易懂

### 3. 个性化程度
- 根据用户角色调整回答
- 结合上下文提供针对性建议
- 保持对话连贯性

## 📝 测试检查清单

- [ ] 基础教授推荐功能正常
- [ ] 深入了解功能能识别教授名称
- [ ] 代词指代解析准确
- [ ] 教授对比分析逻辑清晰
- [ ] 学术建议针对性强
- [ ] 上下文传递机制正常
- [ ] 实体识别准确率高
- [ ] 响应元数据正确保存
- [ ] AI简化功能集成良好
- [ ] 边界情况处理恰当
- [ ] 用户体验流畅自然

## 🔧 调试说明

查看控制台日志关键信息：
1. `发送上下文:` - 验证上下文构建
2. `消息类型:` - 验证意图识别  
3. `上下文实体:` - 验证实体提取
4. `已保存响应元数据:` - 验证元数据保存

这样的系统才是真正的智能对话助手！🚀
